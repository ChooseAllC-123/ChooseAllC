{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccc091fa-de47-49bf-8446-6bc5c8d20ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "019e0472-c6a7-4ff2-ae75-d9ab4edb342c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved to F:\\PhD\\RA\\Schafer\\IRA\\data\\transformed\\cleaned_data2.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Define the file path\n",
    "file_path = r\"F:\\PhD\\RA\\Schafer\\IRA\\data\\transformed\\combined_2_cleaned.xlsx\"\n",
    "\n",
    "# Load the Excel file\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Define the columns to keep and their new names\n",
    "columns_to_keep = {\n",
    "    \"Citeline Drug ID\": \"drugid\",\n",
    "    \"Generic Drug Name\": \"drugprimaryname\",\n",
    "    \"Drug Names\": \"drugnamesynonyms\",\n",
    "    \"Event Date\": \"eventdate\",\n",
    "    \"Event Type\": \"eventtype\",\n",
    "    \"Event Details\": \"eventdetails\",\n",
    "    \"Drug Type\": \"origin\",\n",
    "    \"NCE\": \"nce\",\n",
    "    \"Therapeutic Class\": \"therapeuticclasses\",\n",
    "    \"Mechanism Of Action\": \"mechanismsofaction\"\n",
    "}\n",
    "\n",
    "# Filter and rename the columns\n",
    "df_cleaned = df[list(columns_to_keep.keys())].rename(columns=columns_to_keep)\n",
    "\n",
    "# Backup original eventdate column\n",
    "df_cleaned[\"eventdate_original\"] = df_cleaned[\"eventdate\"]\n",
    "\n",
    "# Convert eventdate to datetime format (assuming it's in YYYY/MM/DD format)\n",
    "df_cleaned[\"eventdate\"] = pd.to_datetime(df_cleaned[\"eventdate\"], format=\"%Y/%m/%d\", errors=\"coerce\")\n",
    "\n",
    "# Convert to YYYY-MM-DD format\n",
    "df_cleaned[\"eventdate\"] = df_cleaned[\"eventdate\"].dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Define the output file path\n",
    "output_file_path = r\"F:\\PhD\\RA\\Schafer\\IRA\\data\\transformed\\cleaned_data2.xlsx\"\n",
    "\n",
    "# Save the cleaned data to a new Excel file\n",
    "df_cleaned.to_excel(output_file_path, index=False)\n",
    "\n",
    "print(f\"Cleaned data saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a340726-69c3-4c64-ad2b-28868a02c4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved to F:\\PhD\\RA\\Schafer\\IRA\\data\\transformed\\cleaned_data1.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Define file paths\n",
    "input_file = r\"F:\\PhD\\RA\\Schafer\\IRA\\data\\transformed\\transformed_data1.xlsx\"\n",
    "output_file = r\"F:\\PhD\\RA\\Schafer\\IRA\\data\\transformed\\cleaned_data1.xlsx\"\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_excel(input_file)\n",
    "\n",
    "# Rename the specified columns\n",
    "df.rename(columns={\n",
    "    \"Event Date\": \"eventdate\",\n",
    "    \"Event Type\": \"eventtype\",\n",
    "    \"Event Details\": \"eventdetails\"\n",
    "}, inplace=True)\n",
    "\n",
    "# Define the columns to keep\n",
    "columns_to_keep = [\n",
    "    \"drugid\",\n",
    "    \"drugprimaryname\",\n",
    "    \"drugnamesynonyms\",\n",
    "    \"eventdate\",\n",
    "    \"eventtype\",\n",
    "    \"eventdetails\",\n",
    "    \"origin\",\n",
    "    \"nce\",\n",
    "    \"therapeuticclasses\",\n",
    "    \"mechanismsofaction\"\n",
    "]\n",
    "\n",
    "# Filter the dataset to keep only these columns\n",
    "df_cleaned = df[columns_to_keep].copy()  # Use .copy() to avoid modifying original df\n",
    "\n",
    "# Backup original eventdate column\n",
    "df_cleaned[\"eventdate_original\"] = df_cleaned[\"eventdate\"]\n",
    "\n",
    "# Convert `eventdate` to datetime format, handling \"T00:00:00Z\" issue\n",
    "df_cleaned[\"eventdate\"] = df_cleaned[\"eventdate\"].astype(str).str.replace(r\"T\\d{2}:\\d{2}:\\d{2}Z\", \"\", regex=True)\n",
    "df_cleaned[\"eventdate\"] = pd.to_datetime(df_cleaned[\"eventdate\"], errors=\"coerce\")  # Convert to datetime\n",
    "df_cleaned[\"eventdate\"] = df_cleaned[\"eventdate\"].dt.strftime(\"%Y-%m-%d\")  # Standardize format\n",
    "\n",
    "# Save the cleaned data to a new file\n",
    "df_cleaned.to_excel(output_file, index=False)\n",
    "\n",
    "print(f\"Cleaned data saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32baedec-87d0-4345-8730-ad1e9a3a2bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined cleaned data saved to F:\\PhD\\RA\\Schafer\\IRA\\data\\transformed\\all.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Define file paths\n",
    "file1 = r\"F:\\PhD\\RA\\Schafer\\IRA\\data\\transformed\\cleaned_data1.xlsx\"\n",
    "file2 = r\"F:\\PhD\\RA\\Schafer\\IRA\\data\\transformed\\cleaned_data2.xlsx\"\n",
    "output_file = r\"F:\\PhD\\RA\\Schafer\\IRA\\data\\transformed\\all.xlsx\"\n",
    "\n",
    "# Load both cleaned datasets\n",
    "df1 = pd.read_excel(file1)\n",
    "df2 = pd.read_excel(file2)\n",
    "\n",
    "# Append the datasets\n",
    "df_combined = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "# Save the combined data\n",
    "df_combined.to_excel(output_file, index=False)\n",
    "\n",
    "print(f\"Combined cleaned data saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a231751-57f4-44ab-9a10-185eef82e2dc",
   "metadata": {},
   "source": [
    "## Data Reformating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa51a7d8-acb2-4637-801c-88344cffbc69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yizho\\AppData\\Local\\Temp\\ipykernel_11404\\1526404558.py:14: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[\"nce\"] = df[\"nce\"].replace({\"Yes\": 1, \"No\": 0}).fillna(0).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatted data saved to F:\\PhD\\RA\\Schafer\\IRA\\data\\transformed\\check.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Define file paths\n",
    "input_file = r\"F:\\PhD\\RA\\Schafer\\IRA\\data\\transformed\\all.xlsx\"\n",
    "output_file = r\"F:\\PhD\\RA\\Schafer\\IRA\\data\\transformed\\all_formatted.xlsx\"\n",
    "check_file = r\"F:\\PhD\\RA\\Schafer\\IRA\\data\\transformed\\check.xlsx\"\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_excel(input_file)\n",
    "\n",
    "# Ensure 'eventdate' remains a datetime type (Only if necessary)\n",
    "# if not pd.api.types.is_datetime64_any_dtype(df[\"eventdate\"]):\n",
    "#    df[\"eventdate\"] = pd.to_datetime(df[\"eventdate\"], errors='coerce')\n",
    "\n",
    "# Standardize 'nce' column: Yes → 1, No → 0, Missing → 0\n",
    "df[\"nce\"] = df[\"nce\"].replace({\"Yes\": 1, \"No\": 0}).fillna(0).astype(int)\n",
    "\n",
    "# Create 'bio' column: 1 if 'origin' contains \"biological\" (case insensitive), else 0\n",
    "df[\"bio\"] = df[\"origin\"].astype(str).str.contains(\"biological\", case=False, na=False).astype(int)\n",
    "\n",
    "# Create 'pass' column (1 if eventdate >= 2021-11-19, else 0)\n",
    "df[\"pass\"] = (df[\"eventdate\"] >= \"2021-11-19\").astype(int)\n",
    "\n",
    "# Create 'effective' column (1 if eventdate >= 2022-08-16, else 0)\n",
    "df[\"effective\"] = (df[\"eventdate\"] >= \"2022-08-16\").astype(int)\n",
    "\n",
    "# Save the modified dataset\n",
    "df.to_excel(check_file, index=False)\n",
    "\n",
    "print(f\"Formatted data saved to {check_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab8fe8e0-2cd3-401c-b990-145841a58674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered dataset saved to F:\\PhD\\RA\\Schafer\\IRA\\data\\transformed\\all_formatted.xlsx, keeping all rows for drugs with 'approval' or 'launch' events.\n"
     ]
    }
   ],
   "source": [
    "# Find all drug IDs where eventtype contains \"approval\" or \"launch\" (case insensitive)\n",
    "matching_drug_ids = df[df[\"eventtype\"].astype(str).str.contains(\"approval|launch\", case=False, na=False)][\"drugid\"].unique()\n",
    "\n",
    "# Filter the dataset to keep only rows with those drug IDs\n",
    "df_filtered = df[df[\"drugid\"].isin(matching_drug_ids)]\n",
    "\n",
    "# Save the filtered dataset\n",
    "df_filtered.to_excel(output_file, index=False)\n",
    "\n",
    "print(f\"Filtered dataset saved to {output_file}, keeping all rows for drugs with 'approval' or 'launch' events.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86ab8251-702f-4d5a-a841-2bfac1540b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered dataset saved to F:\\PhD\\RA\\Schafer\\IRA\\data\\transformed\\all_disease.xlsx, contains dieases number and post indicator\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Define file paths\n",
    "input_file = r\"F:\\PhD\\RA\\Schafer\\IRA\\data\\transformed\\all_formatted.xlsx\"\n",
    "output_file = r\"F:\\PhD\\RA\\Schafer\\IRA\\data\\transformed\\all_disease.xlsx\"\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_excel(input_file)\n",
    "\n",
    "\n",
    "# Function to count diseases correctly\n",
    "def count_diseases(row):\n",
    "    if row[\"eventtype\"] != \"New Disease\":\n",
    "        return 0\n",
    "    \n",
    "    event_details = str(row[\"eventdetails\"]).strip().rstrip(\";\")\n",
    "\n",
    "    if not event_details or event_details.lower() == \"nan\":\n",
    "        return 1\n",
    "\n",
    "    # Split on actual delimiters only\n",
    "    parts = re.split(r\"\\s*(?:;|&| and )\\s*\", event_details)\n",
    "    parts = [p.strip() for p in parts if p.strip()]\n",
    "\n",
    "    return len(parts)\n",
    "    \n",
    "# Apply function to create `diseasenum` column\n",
    "df[\"diseasenum\"] = df.apply(count_diseases, axis=1)\n",
    "\n",
    "def count_usapp(row):\n",
    "    if row[\"eventtype\"] != \"Supplemental Approval\":\n",
    "        return 0  # Only process Supplemental Approval events\n",
    "\n",
    "    details = str(row[\"eventdetails\"])\n",
    "\n",
    "    # Check if \"US;\" or \"USA;\" is contained anywhere\n",
    "    if \"US;\" not in details and \"USA;\" not in details:\n",
    "        return 0\n",
    "\n",
    "    # Clean and normalize the string\n",
    "    details = details.strip().rstrip(\";\")\n",
    "\n",
    "    # Count semicolons\n",
    "    semicolon_count = details.count(\";\")\n",
    "\n",
    "    if semicolon_count <= 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return semicolon_count - 1  # Subtract 1 for the \"US;\" or \"USA;\" presence\n",
    "\n",
    "df[\"usapp\"] = df.apply(count_usapp, axis=1)\n",
    "\n",
    "# Step 1: Get First Approval date\n",
    "first_approval = (\n",
    "    df[df[\"eventtype\"] == \"First Approval\"]\n",
    "    .groupby(\"drugid\")[\"eventdate\"]\n",
    "    .min()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"eventdate\": \"first_approval_date\"})\n",
    ")\n",
    "\n",
    "# Step 2: Get First Launch date\n",
    "first_launch = (\n",
    "    df[df[\"eventtype\"] == \"First Launch\"]\n",
    "    .groupby(\"drugid\")[\"eventdate\"]\n",
    "    .min()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"eventdate\": \"first_launch_date\"})\n",
    ")\n",
    "\n",
    "# Step 3: Merge both into main dataframe\n",
    "df = df.merge(first_approval, on=\"drugid\", how=\"left\")\n",
    "df = df.merge(first_launch, on=\"drugid\", how=\"left\")\n",
    "\n",
    "# Step 4: Define fallback first_approval_date (use Launch if Approval is missing)\n",
    "df[\"first_approval_or_launch\"] = df[\"first_approval_date\"].combine_first(df[\"first_launch_date\"])\n",
    "\n",
    "# Step 5: Create `postapp` flag\n",
    "df[\"postapp\"] = (df[\"eventdate\"] > df[\"first_approval_or_launch\"]).astype(int)\n",
    "\n",
    "# Save the filtered dataset\n",
    "df.to_excel(output_file, index=False)\n",
    "\n",
    "print(f\"Filtered dataset saved to {output_file}, contains dieases number and post indicator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2eba33e7-a671-44a1-9be0-e05b6a40503d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = r\"F:\\PhD\\RA\\Schafer\\IRA\\data\\transformed\\all_disease.xlsx\"\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_excel(input_file)\n",
    "\n",
    "# Step 1: Create `phaseii` column\n",
    "df[\"phaseii\"] = df[\"eventdetails\"].astype(str).str.contains(r\"phase\\s*ii|phase\\s*2\", case=False, na=False).astype(int)\n",
    "\n",
    "# Step 2: Create `phaseiii` column\n",
    "df[\"phaseiii\"] = df[\"eventdetails\"].astype(str).str.contains(r\"phase\\s*iii|phase\\s*3\", case=False, na=False).astype(int)\n",
    "\n",
    "# Step 3: Fix `phaseii` where `phaseiii = 1` to prevent double-counting\n",
    "df.loc[df[\"phaseiii\"] == 1, \"phaseii\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30166372-04e4-4efa-b8db-d7f208100f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered dataset saved to F:\\PhD\\RA\\Schafer\\IRA\\data\\transformed\\all_complete.xlsx, contains dieases number and post indicator\n"
     ]
    }
   ],
   "source": [
    "output_file = r\"F:\\PhD\\RA\\Schafer\\IRA\\data\\transformed\\all_complete.xlsx\"\n",
    "# Save the filtered dataset\n",
    "df.to_excel(output_file, index=False)\n",
    "\n",
    "print(f\"Filtered dataset saved to {output_file}, contains dieases number and post indicator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cccf55de-16ac-49b9-bd27-f571bc896e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered data for drugid 5940 saved to:\n",
      "F:\\PhD\\RA\\Schafer\\IRA\\data\\check\\5940.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Define file paths\n",
    "input_file = r\"F:\\PhD\\RA\\Schafer\\IRA\\data\\transformed\\all_complete.xlsx\"\n",
    "output_file = r\"F:\\PhD\\RA\\Schafer\\IRA\\data\\check\\5940.xlsx\"\n",
    "\n",
    "# Step 2: Read the input file\n",
    "df = pd.read_excel(input_file)\n",
    "\n",
    "# Step 3: Filter for drugid == 69763\n",
    "df_filtered = df[df[\"drugid\"] == 5940]\n",
    "\n",
    "# Step 4: Save the filtered result\n",
    "df_filtered.to_excel(output_file, index=False)\n",
    "\n",
    "print(f\"Filtered data for drugid 5940 saved to:\\n{output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d333718b-e89b-43fe-9127-f52614913dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Updated dataset saved to: F:\\PhD\\RA\\Schafer\\IRA\\data\\transformed\\all_complete_with_usflags.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Define file paths\n",
    "input_file = r\"F:\\PhD\\RA\\Schafer\\IRA\\data\\transformed\\all_complete.xlsx\"\n",
    "df = pd.read_excel(input_file)\n",
    "\n",
    "# Filter rows with \"Approval\" or \"Launch\" in `eventtype` AND \"US;\" in `eventdetails`\n",
    "us_approval_events = df[\n",
    "    df[\"eventtype\"].str.contains(\"Approval|Launch\", case=True, na=False) &\n",
    "    df[\"eventdetails\"].str.contains(\"US\", case=True, na=False)\n",
    "]\n",
    "\n",
    "# For each drugid, find the earliest matching `eventdate`\n",
    "us_approval_dates = (\n",
    "    us_approval_events.groupby(\"drugid\")[\"eventdate\"]\n",
    "    .min()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"eventdate\": \"usapprovaldate\"})\n",
    ")\n",
    "\n",
    "# Merge the result back into the original dataframe\n",
    "df = df.merge(us_approval_dates, on=\"drugid\", how=\"left\")\n",
    "\n",
    "def count_us_new_approval(row):\n",
    "    if row[\"eventtype\"] != \"New Approval\":\n",
    "        return 0\n",
    "\n",
    "    details = str(row[\"eventdetails\"]).strip().rstrip(\";\")\n",
    "    \n",
    "    if \"US;\" not in details:\n",
    "        return 0\n",
    "\n",
    "    return details.count(\";\")\n",
    "\n",
    "# Apply the function to create a new column\n",
    "df[\"us_new_approval\"] = df.apply(count_us_new_approval, axis=1)\n",
    "\n",
    "# Column: has_us_approval\n",
    "df[\"has_us_approval\"] = ((df[\"us_new_approval\"] + df[\"usapp\"]) > 0).astype(int)\n",
    "\n",
    "# Column: has_disease\n",
    "df[\"has_disease\"] = (df[\"diseasenum\"] > 0).astype(int)\n",
    "\n",
    "df[\"postapp\"] = (df[\"eventdate\"] > df[\"usapprovaldate\"]).astype(int)\n",
    "\n",
    "output_path = r\"F:\\PhD\\RA\\Schafer\\IRA\\data\\transformed\\all_complete_with_usflags.xlsx\"\n",
    "df.to_excel(output_path, index=False)\n",
    "print(f\"✅ Updated dataset saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d608561b-10b0-4c54-923d-d96a03dfaa36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
