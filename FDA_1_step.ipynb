{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d2f7e81-6d6f-4e3f-abed-a10f57ae9155",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import glob\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c8b3d6-d71a-4b2d-a0c2-d474d3bd6961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download complete!\n"
     ]
    }
   ],
   "source": [
    "# Set your download directory\n",
    "download_dir = r\"F:\\PhD\\RA\\Schafer\\IRA\\data\"\n",
    "\n",
    "# Configure Chrome options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_experimental_option(\"prefs\", {\n",
    "    \"download.default_directory\": download_dir,         # Change default download location\n",
    "    \"download.prompt_for_download\": False,              # Disable download prompt\n",
    "    \"directory_upgrade\": True,\n",
    "    \"safebrowsing.enabled\": True\n",
    "})\n",
    "\n",
    "# Optional: Run in headless mode\n",
    "# chrome_options.add_argument(\"--headless\")\n",
    "\n",
    "# Start Chrome\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "try:\n",
    "    # Go to the page\n",
    "    url = \"https://www.fda.gov/drugs/drug-approvals-and-databases/drugsfda-data-files#download\"\n",
    "    driver.get(url)\n",
    "    time.sleep(3)  # Wait for the page to load\n",
    "\n",
    "    # Find and click the download link\n",
    "    download_link = driver.find_element(By.PARTIAL_LINK_TEXT, \"Drugs@FDA Download File\")\n",
    "    download_link.click()\n",
    "    time.sleep(10)  # Wait for the download to complete (adjust as needed)\n",
    "\n",
    "finally:\n",
    "    driver.quit()\n",
    "\n",
    "print(\"Download complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ad37431-a0a0-40de-9fb1-104b93630562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ZIP file: F:\\PhD\\RA\\Schafer\\IRA\\data\\daf05212025.zip\n",
      "Unzipped all files to: F:\\PhD\\RA\\Schafer\\IRA\\data\\unzipped\n"
     ]
    }
   ],
   "source": [
    "# Folder where the file is downloaded\n",
    "download_dir = r\"F:\\PhD\\RA\\Schafer\\IRA\\data\"\n",
    "\n",
    "# Get list of zip files and sort by modification time (descending)\n",
    "zip_files = glob.glob(os.path.join(download_dir, \"*.zip\"))\n",
    "latest_zip = max(zip_files, key=os.path.getmtime)\n",
    "print(\"Using ZIP file:\", latest_zip)\n",
    "\n",
    "extract_dir = os.path.join(download_dir, \"unzipped\")\n",
    "os.makedirs(extract_dir, exist_ok=True)\n",
    "\n",
    "with zipfile.ZipFile(latest_zip, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_dir)\n",
    "\n",
    "print(\"Unzipped all files to:\", extract_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6309bf29-9174-48a1-add1-e25876f9d0c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted F:\\PhD\\RA\\Schafer\\IRA\\data\\unzipped\\ActionTypes_Lookup.txt -> F:\\PhD\\RA\\Schafer\\IRA\\data\\unzipped\\ActionTypes_Lookup.xlsx\n",
      "Converted F:\\PhD\\RA\\Schafer\\IRA\\data\\unzipped\\ApplicationDocs.txt -> F:\\PhD\\RA\\Schafer\\IRA\\data\\unzipped\\ApplicationDocs.xlsx\n",
      "Converted F:\\PhD\\RA\\Schafer\\IRA\\data\\unzipped\\Applications.txt -> F:\\PhD\\RA\\Schafer\\IRA\\data\\unzipped\\Applications.xlsx\n",
      "Converted F:\\PhD\\RA\\Schafer\\IRA\\data\\unzipped\\ApplicationsDocsType_Lookup.txt -> F:\\PhD\\RA\\Schafer\\IRA\\data\\unzipped\\ApplicationsDocsType_Lookup.xlsx\n",
      "Converted F:\\PhD\\RA\\Schafer\\IRA\\data\\unzipped\\Join_Submission_ActionTypes_Lookup.txt -> F:\\PhD\\RA\\Schafer\\IRA\\data\\unzipped\\Join_Submission_ActionTypes_Lookup.xlsx\n",
      "Converted F:\\PhD\\RA\\Schafer\\IRA\\data\\unzipped\\MarketingStatus.txt -> F:\\PhD\\RA\\Schafer\\IRA\\data\\unzipped\\MarketingStatus.xlsx\n",
      "Converted F:\\PhD\\RA\\Schafer\\IRA\\data\\unzipped\\MarketingStatus_Lookup.txt -> F:\\PhD\\RA\\Schafer\\IRA\\data\\unzipped\\MarketingStatus_Lookup.xlsx\n",
      "Converted F:\\PhD\\RA\\Schafer\\IRA\\data\\unzipped\\Products.txt -> F:\\PhD\\RA\\Schafer\\IRA\\data\\unzipped\\Products.xlsx\n",
      "Converted F:\\PhD\\RA\\Schafer\\IRA\\data\\unzipped\\SubmissionClass_Lookup.txt -> F:\\PhD\\RA\\Schafer\\IRA\\data\\unzipped\\SubmissionClass_Lookup.xlsx\n",
      "Converted F:\\PhD\\RA\\Schafer\\IRA\\data\\unzipped\\SubmissionPropertyType.txt -> F:\\PhD\\RA\\Schafer\\IRA\\data\\unzipped\\SubmissionPropertyType.xlsx\n",
      "Converted F:\\PhD\\RA\\Schafer\\IRA\\data\\unzipped\\Submissions.txt -> F:\\PhD\\RA\\Schafer\\IRA\\data\\unzipped\\Submissions.xlsx\n",
      "Converted F:\\PhD\\RA\\Schafer\\IRA\\data\\unzipped\\TE.txt -> F:\\PhD\\RA\\Schafer\\IRA\\data\\unzipped\\TE.xlsx\n"
     ]
    }
   ],
   "source": [
    "for txt_file in txt_files:\n",
    "    # Try to read with fallback encoding and skip bad lines\n",
    "    try:\n",
    "        df = pd.read_csv(txt_file, sep='\\t', header=None, dtype=str, encoding=\"utf-8\", on_bad_lines='skip')\n",
    "    except UnicodeDecodeError:\n",
    "        df = pd.read_csv(txt_file, sep='\\t', header=None, dtype=str, encoding=\"latin1\", on_bad_lines='skip')\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {txt_file}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Set first row as header\n",
    "    new_header = df.iloc[0]\n",
    "    df = df[1:]\n",
    "    df.columns = new_header\n",
    "\n",
    "    # Drop empty columns (optional, for cleaner Excel)\n",
    "    # df = df.dropna(axis=1, how='all')\n",
    "    # df = df.loc[:, ~(df == '').all()]\n",
    "\n",
    "    # Save to Excel\n",
    "    excel_name = os.path.splitext(os.path.basename(txt_file))[0] + \".xlsx\"\n",
    "    excel_path = os.path.join(extract_dir, excel_name)\n",
    "    df.to_excel(excel_path, index=False)\n",
    "    print(f\"Converted {txt_file} -> {excel_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed65f264-bbff-49f6-8cf0-4bea087e20e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_path = r\"F:\\PhD\\RA\\Schafer\\IRA\\data\\unzipped\\Products.xlsx\"\n",
    "subm_path = r\"F:\\PhD\\RA\\Schafer\\IRA\\data\\unzipped\\Submissions.xlsx\"\n",
    "appl_path = r\"F:\\PhD\\RA\\Schafer\\IRA\\data\\unzipped\\ApplicationDocs.xlsx\"\n",
    "act_path = r\"F:\\PhD\\RA\\Schafer\\IRA\\data\\unzipped\\Join_Submission_ActionTypes_Lookup.xlsx\"\n",
    "out_path = r\"F:\\PhD\\RA\\Schafer\\IRA\\data\\unzipped\\integrated_file.xlsx\"\n",
    "applty_path = r\"F:\\PhD\\RA\\Schafer\\IRA\\data\\unzipped\\Applications.xlsx\"\n",
    "df_prod = pd.read_excel(prod_path)\n",
    "df_subm = pd.read_excel(subm_path)\n",
    "df_appl = pd.read_excel(appl_path)\n",
    "df_act = pd.read_excel(act_path)\n",
    "df_applty = pd.read_excel(applty_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91e236db-a642-4c78-97c5-b1864bdeb176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_prod ApplNo dtype: Int64 sample: <IntegerArray>\n",
      "[4, 159, 552, 734, 793]\n",
      "Length: 5, dtype: Int64\n",
      "df_subm ApplNo dtype: Int64 sample: <IntegerArray>\n",
      "[4, 159, 415, 552, 654]\n",
      "Length: 5, dtype: Int64\n",
      "df_appl ApplNo dtype: Int64 sample: <IntegerArray>\n",
      "[4782, 5010, 5213, 5378, 5619]\n",
      "Length: 5, dtype: Int64\n",
      "df_act ApplNo dtype: Int64 sample: <IntegerArray>\n",
      "[17866, 71450, 17514, 14716, 18276]\n",
      "Length: 5, dtype: Int64\n",
      "df_applty ApplNo dtype: Int64 sample: <IntegerArray>\n",
      "[4, 159, 552, 734, 793]\n",
      "Length: 5, dtype: Int64\n"
     ]
    }
   ],
   "source": [
    "keys = ['ApplNo', 'SubmissionType', 'SubmissionNo']\n",
    "dfs = [df_prod, df_subm, df_appl, df_act, df_applty]\n",
    "names = ['df_prod', 'df_subm', 'df_appl', 'df_act', 'df_applty']\n",
    "\n",
    "for df, name in zip(dfs, names):\n",
    "    if 'ApplNo' in df.columns:\n",
    "        # Remove whitespace, then convert to integer\n",
    "        df['ApplNo'] = df['ApplNo'].astype(str).str.strip()\n",
    "        # If any 'nan', replace with None to avoid conversion error\n",
    "        df['ApplNo'] = df['ApplNo'].replace('nan', None)\n",
    "        df['ApplNo'] = df['ApplNo'].astype(float).astype('Int64')  # allows for NaN\n",
    "        print(f\"{name} ApplNo dtype: {df['ApplNo'].dtype} sample: {df['ApplNo'].unique()[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8438994-4e8d-4362-8ffb-a02c33e1d492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data saved to F:\\PhD\\RA\\Schafer\\IRA\\data\\unzipped\\merge\\merged4.xlsx\n"
     ]
    }
   ],
   "source": [
    "# df_prod: Products DataFrame\n",
    "# df_subm: Submissions DataFrame\n",
    "\n",
    "merged1 = pd.merge(df_prod, df_subm, how='outer', on='ApplNo')\n",
    "merged2 = pd.merge(merged1, df_applty, how='outer', on='ApplNo')\n",
    "merged3 = pd.merge(\n",
    "    merged2,\n",
    "    df_appl,\n",
    "    how='outer',  # or 'left', 'right', 'outer' as you need\n",
    "    on=['ApplNo', 'SubmissionType', 'SubmissionNo']\n",
    ")\n",
    "merged4 = pd.merge(\n",
    "    merged3,\n",
    "    df_act,\n",
    "    how='outer',  # or 'left', 'right', 'outer' as you need\n",
    "    on=['ApplNo', 'SubmissionType', 'SubmissionNo']\n",
    ")\n",
    "\n",
    "output_path = r\"F:\\PhD\\RA\\Schafer\\IRA\\data\\unzipped\\merge\\merged4.xlsx\"\n",
    "merged4.to_excel(output_path, index=False)\n",
    "print(f\"Merged data saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7cf59e8-b13e-45a7-a67c-ad7aac9f04b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dates cleaned and saved to: F:\\PhD\\RA\\Schafer\\IRA\\data\\unzipped\\merge\\merged4_modified.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File path\n",
    "file_path = r\"F:\\PhD\\RA\\Schafer\\IRA\\data\\unzipped\\merge\\merged4.xlsx\"\n",
    "\n",
    "# Read the Excel file\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Convert 'SubmissionStatusDate' and 'ApplicationDocsDate' to datetime (if not already)\n",
    "df['SubmissionStatusDate'] = pd.to_datetime(df['SubmissionStatusDate'])\n",
    "df['ApplicationDocsDate'] = pd.to_datetime(df['ApplicationDocsDate'])\n",
    "\n",
    "# Keep only the date part (remove time)\n",
    "df['SubmissionStatusDate'] = df['SubmissionStatusDate'].dt.date\n",
    "df['ApplicationDocsDate'] = df['ApplicationDocsDate'].dt.date\n",
    "\n",
    "# If you want to save the modified DataFrame back to Excel\n",
    "output_file_path = r\"F:\\PhD\\RA\\Schafer\\IRA\\data\\unzipped\\merge\\merged4_modified.xlsx\"\n",
    "df.to_excel(output_file_path, index=False)\n",
    "\n",
    "print(\"Dates cleaned and saved to:\", output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0d906a-eb43-47ef-a725-750d67b1f345",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
