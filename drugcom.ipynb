{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9872e440-c0e3-43cd-9b26-9c592f57ef39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download complete!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "# Set your download directory\n",
    "download_dir = r\"F:\\PhD\\RA\\Schafer\\IRA\\data\\nme\"\n",
    "\n",
    "# Chrome options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_experimental_option(\"prefs\", {\n",
    "    \"download.default_directory\": download_dir,\n",
    "    \"download.prompt_for_download\": False,\n",
    "    \"directory_upgrade\": True,\n",
    "    \"safebrowsing.enabled\": True\n",
    "})\n",
    "\n",
    "# Start Chrome\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "try:\n",
    "    # Go to the target FDA compilation page\n",
    "    url = \"https://www.fda.gov/drugs/drug-approvals-and-databases/compilation-cder-new-molecular-entity-nme-drug-and-new-biologic-approvals\"\n",
    "    driver.get(url)\n",
    "    time.sleep(3)  # Let page load\n",
    "\n",
    "    # Find and click the link by its partial link text\n",
    "    # If you want it 100% robust, use the full visible link text below:\n",
    "    link_text = \"Compilation of CDER NME and New Biologic Approvals 1985-2023\"\n",
    "    download_link = driver.find_element(By.PARTIAL_LINK_TEXT, link_text)\n",
    "    download_link.click()\n",
    "    time.sleep(15)  # Wait for the download to complete (increase if your network is slow)\n",
    "\n",
    "finally:\n",
    "    driver.quit()\n",
    "\n",
    "print(\"Download complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "63110fa2-ad0b-44c5-80da-ae95966d96d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_path = r\"F:\\PhD\\RA\\Schafer\\IRA\\data\\nme\\compilation_of_cder_nme_and_new_biologic_approvals_1985-2023.csv\"\n",
    "output_path = r\"F:\\PhD\\RA\\Schafer\\IRA\\data\\nme\\nme_approved_2020onward.xlsx\"\n",
    "\n",
    "# Read the CSV\n",
    "df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a3d48622-137f-44c7-95f3-63b52a19c080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date\n",
    "df['FDA Approval Date'] = pd.to_datetime(df['FDA Approval Date'], errors='coerce')\n",
    "# Filter for 2020+\n",
    "df_filtered = df[df['FDA Approval Date'].dt.year >= 2000].copy()\n",
    "# Rename\n",
    "df_filtered.rename(columns={'Proprietary  Name': 'drugname'}, inplace=True)\n",
    "# Save\n",
    "df_filtered[['drugname', 'FDA Approval Date']].to_excel(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "15839d92-9466-49d4-a423-d2a6f4ce2bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up drug names for the URL (lowercase, strip spaces, etc.)\n",
    "df_filtered['drug_url'] = df_filtered['drugname'].str.strip().str.lower().str.replace(' ', '-')\n",
    "df_filtered['drug_url'] = \"https://www.drugs.com/history/\" + df_filtered['drug_url'] + \".html\"\n",
    "\n",
    "df_filtered[['drugname', 'FDA Approval Date', 'drug_url']].to_excel(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8fcb29aa-a357-4fb7-98e2-4c9323bf512c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing evoxac...\n",
      "Processing trileptal...\n",
      "Processing protonix...\n",
      "Processing lotronex...\n",
      "Processing skin-exposure-reduction-paste-against-chemical-warfare-agents-(serpacwa)...\n",
      "Processing zonegran...\n",
      "Processing septocaine...\n",
      "Processing visudyne...\n",
      "Processing mobic...\n",
      "Processing zyvox...\n",
      "Processing lantus...\n",
      "Processing exelon...\n",
      "Processing mylotarg...\n",
      "Processing welchol...\n",
      "Processing tnkase...\n",
      "Processing novolog...\n",
      "Processing trelstar-depot...\n",
      "Processing acova...\n",
      "Processing innohep...\n",
      "Processing colazal...\n",
      "Processing abreva...\n",
      "Processing rescula...\n",
      "Processing cetrotide...\n",
      "Processing kaletra...\n",
      "Processing trisenox...\n",
      "Processing mifeprex...\n",
      "Processing myobloc...\n",
      "Processing angiomax...\n",
      "Processing starlix...\n",
      "Processing peg-intron...\n",
      "Processing cancidas...\n",
      "Processing geodon...\n",
      "Processing foradil...\n",
      "Processing reminyl...\n",
      "Processing travatan...\n",
      "Processing lumigan...\n",
      "Processing campath...\n",
      "Processing axert...\n",
      "Processing gleevec...\n",
      "Processing yasmin...\n",
      "Error processing yasmin: HTTPSConnectionPool(host='www.drugs.com', port=443): Max retries exceeded with url: /history/yasmin.html (Caused by SSLError(SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1000)')))\n",
      "Processing definity...\n",
      "Processing natrecor...\n",
      "Processing zometa...\n",
      "Processing spectracef...\n",
      "Processing aranesp...\n",
      "Processing nuvaring...\n",
      "Processing viread...\n",
      "Processing frova...\n",
      "Processing kineret...\n",
      "Processing bextra...\n",
      "Processing avodart...\n",
      "Processing ortho-evra...\n",
      "Processing tracleer...\n",
      "Processing invanz...\n",
      "Processing xigris...\n",
      "Processing arixtra...\n",
      "Processing elidel...\n",
      "Processing clarinex...\n",
      "Processing orfadin...\n",
      "Processing neulasta...\n",
      "Processing zevalin...\n",
      "Processing rebif...\n",
      "Processing faslodex...\n",
      "Processing benicar...\n",
      "Processing remodulin...\n",
      "Processing vfend...\n",
      "Processing imagent...\n",
      "Processing elitek...\n",
      "Processing xyrem...\n",
      "Processing zelnorm...\n",
      "Processing eloxatin...\n",
      "Processing hepsera...\n",
      "Processing inspra...\n",
      "Processing pegasys...\n",
      "Processing zetia...\n",
      "Processing abilify...\n",
      "Processing alinia...\n",
      "Processing strattera...\n",
      "Processing extraneal...\n",
      "Processing relpax...\n",
      "Processing humira...\n",
      "Processing amevive...\n",
      "Processing fuzeon...\n",
      "Processing somavert...\n",
      "Processing emend...\n",
      "Processing factive...\n",
      "Processing fabrazyme...\n",
      "Processing aldurazyme...\n",
      "Processing iressa...\n",
      "Processing velcade...\n",
      "Processing boniva...\n",
      "Processing uroxatral...\n",
      "Processing reyataz...\n",
      "Processing xolair...\n",
      "Processing bexxar...\n",
      "Processing emtriva...\n",
      "Processing aloxi...\n",
      "Processing zavesca...\n",
      "Processing crestor...\n",
      "Processing levitra...\n",
      "Processing cubicin...\n",
      "Processing radiogardase...\n",
      "Processing elestat...\n",
      "Processing namenda...\n",
      "Processing raptiva...\n",
      "Processing cialis...\n",
      "Processing plenaxis...\n",
      "Processing ertaczo...\n",
      "Processing spiriva-handihaler...\n",
      "Processing alimta...\n",
      "Processing erbitux...\n",
      "Processing avastin...\n",
      "Processing sensipar...\n",
      "Processing ketek...\n",
      "Processing chirhostim...\n",
      "Processing apidra...\n",
      "Processing apokyn...\n",
      "Processing vitrase...\n",
      "Processing tindamax...\n",
      "Processing vidaza...\n",
      "Processing xifaxan...\n",
      "Processing sanctura...\n",
      "Processing nutrestore...\n",
      "Processing neutrospec...\n",
      "Processing campral...\n",
      "Processing cymbalta...\n",
      "Processing [drug-marketed-without-a-proprietary-name]...\n",
      "Processing amphadase...\n",
      "Processing fosrenol...\n",
      "Processing omacor...\n",
      "Processing tarceva...\n",
      "Processing vesicare...\n",
      "Processing multihance...\n",
      "Processing tysabri...\n",
      "Processing kepivance...\n",
      "Processing lunesta...\n",
      "Processing visionblue...\n",
      "Processing macugen...\n",
      "Processing enablex...\n",
      "Processing prialt...\n",
      "Processing clolar...\n",
      "Processing ventavis...\n",
      "Processing lyrica...\n",
      "Processing symlin...\n",
      "Processing mycamine...\n",
      "Processing baraclude...\n",
      "Processing byetta...\n",
      "Processing naglazyme...\n",
      "Processing tygacil...\n",
      "Processing levemir...\n",
      "Processing aptivus...\n",
      "Processing rozerem...\n",
      "Processing nevanac...\n",
      "Processing increlex...\n",
      "Processing hydase...\n",
      "Processing arranon...\n",
      "Processing exjade...\n",
      "Processing hylenex...\n",
      "Processing iplex...\n",
      "Processing nexavar...\n",
      "Processing orencia...\n",
      "Processing revlimid...\n",
      "Processing vaprisol...\n",
      "Processing sutent...\n",
      "Processing ranexa...\n",
      "Processing amitiza...\n",
      "Processing eraxis...\n",
      "Processing myozyme...\n",
      "Processing dacogen...\n",
      "Processing chantix...\n",
      "Processing azilect...\n",
      "Processing prezista...\n",
      "Processing sprycel...\n",
      "Processing lucentis...\n",
      "Processing anthelios-sx...\n",
      "Processing elaprase...\n",
      "Processing noxafil...\n",
      "Processing vectibix...\n",
      "Processing pylera...\n",
      "Processing zolinza...\n",
      "Processing januvia...\n",
      "Processing omnaris...\n",
      "Processing tyzeka...\n",
      "Processing veregen...\n",
      "Processing invega...\n",
      "Processing vyvanse...\n",
      "Processing tekturna...\n",
      "Processing tykerb...\n",
      "Processing soliris...\n",
      "Processing altabax...\n",
      "Processing neupro...\n",
      "Processing torisel...\n",
      "Processing letairis...\n",
      "Processing selzentry...\n",
      "Processing somatuline-depot...\n",
      "Processing doribax...\n",
      "Processing isentress...\n",
      "Processing ixempra...\n",
      "Processing tasigna...\n",
      "Processing mircera...\n",
      "Processing kuvan...\n",
      "Processing bystolic...\n",
      "Processing intelence...\n",
      "Processing arcalyst...\n",
      "Processing pristiq...\n",
      "Processing treanda...\n",
      "Processing lexiscan...\n",
      "Processing cimzia...\n",
      "Processing relistor...\n",
      "Processing entereg...\n",
      "Processing durezol...\n",
      "Processing eovist...\n",
      "Processing cleviprex...\n",
      "Processing xenazine...\n",
      "Processing nplate...\n",
      "Processing adreview...\n",
      "Processing rapaflo...\n",
      "Processing vimpat...\n",
      "Processing toviaz...\n",
      "Processing banzel...\n",
      "Processing promacta...\n",
      "Processing nucynta...\n",
      "Processing lusedra...\n",
      "Processing mozobil...\n",
      "Processing vasovist...\n",
      "Processing firmagon...\n",
      "Processing savella...\n",
      "Processing uloric...\n",
      "Processing afinitor...\n",
      "Processing coartem...\n",
      "Processing ulesfia...\n",
      "Processing simponi...\n",
      "Processing dysport...\n",
      "Processing fanapt...\n",
      "Processing samsca...\n",
      "Processing besivance...\n",
      "Processing ilaris...\n",
      "Processing multaq...\n",
      "Processing effient...\n",
      "Processing onglyza...\n",
      "Processing livalo...\n",
      "Processing saphris...\n",
      "Processing sabril...\n",
      "Processing bepreve...\n",
      "Processing vibativ...\n",
      "Processing folotyn...\n",
      "Processing stelara...\n",
      "Processing votrient...\n",
      "Processing arzerra...\n",
      "Processing istodax...\n",
      "Processing qutenza...\n",
      "Processing kalbitor...\n",
      "Processing actemra...\n",
      "Processing ampyra...\n",
      "Processing victoza...\n",
      "Processing xiaflex...\n",
      "Processing vpriv...\n",
      "Processing carbaglu...\n",
      "Processing asclera...\n",
      "Processing natazia...\n",
      "Processing lumizyme...\n",
      "Processing prolia...\n",
      "Processing jevtana...\n",
      "Processing lastacaft...\n",
      "Processing xeomin...\n",
      "Processing ella...\n",
      "Processing krystexxa...\n",
      "Processing gilenya...\n",
      "Processing pradaxa...\n",
      "Processing latuda...\n",
      "Processing teflaro...\n",
      "Processing egrifta...\n",
      "Processing halaven...\n",
      "Processing datscan...\n",
      "Processing natroba...\n",
      "Processing viibryd...\n",
      "Processing edarbi...\n",
      "Processing daliresp...\n",
      "Processing benlysta...\n",
      "Processing gadavist...\n",
      "Processing yervoy...\n",
      "Processing caprelsa...\n",
      "Processing horizant...\n",
      "Processing zytiga...\n",
      "Processing tradjenta...\n",
      "Processing victrelis...\n",
      "Processing edurant...\n",
      "Processing incivek...\n",
      "Processing dificid...\n",
      "Processing potiga...\n",
      "Processing nulojix...\n",
      "Processing arcapta-neohaler...\n",
      "Processing xarelto...\n",
      "Processing brilinta...\n",
      "Processing zelboraf...\n",
      "Processing adcetris...\n",
      "Processing firazyr...\n",
      "Processing xalkori...\n",
      "Processing ferriprox...\n",
      "Processing onfi...\n",
      "Processing jakafi...\n",
      "Processing erwinaze...\n",
      "Processing eylea...\n",
      "Processing voraxaze...\n",
      "Processing picato...\n",
      "Processing inlyta...\n",
      "Processing erivedge...\n",
      "Processing kalydeco...\n",
      "Processing zioptan...\n",
      "Processing surfaxin...\n",
      "Processing omontys...\n",
      "Processing amyvid...\n",
      "Processing stendra...\n",
      "Processing elelyso...\n",
      "Processing perjeta...\n",
      "Processing belviq...\n",
      "Processing myrbetriq...\n",
      "Processing prepopik...\n",
      "Processing kyprolis...\n",
      "Processing tudorza-pressair...\n",
      "Processing zaltrap...\n",
      "Processing stribild...\n",
      "Processing granix...\n",
      "Processing linzess...\n",
      "Processing xtandi...\n",
      "Processing bosulif...\n",
      "Processing aubagio...\n",
      "Processing stivarga...\n",
      "Processing jetrea...\n",
      "Processing fycompa...\n",
      "Processing synribo...\n",
      "Processing xeljanz...\n",
      "Processing cometriq...\n",
      "Processing signifor...\n",
      "Processing iclusig...\n",
      "Processing juxtapid...\n",
      "Processing gattex...\n",
      "Processing eliquis...\n",
      "Processing sirturo...\n",
      "Processing fulyzaq...\n",
      "Processing nesina...\n",
      "Processing kynamro...\n",
      "Processing pomalyst...\n",
      "Processing kadcyla...\n",
      "Processing osphena...\n",
      "Processing lymphoseek...\n",
      "Processing dotarem...\n",
      "Processing tecfidera...\n",
      "Processing invokana...\n",
      "Processing breo-ellipta...\n",
      "Processing xofigo...\n",
      "Processing tafinlar...\n",
      "Processing mekinist...\n",
      "Processing gilotrif...\n",
      "Processing tivicay...\n",
      "Processing brintellix...\n",
      "Processing duavee...\n",
      "Processing adempas...\n",
      "Processing opsumit...\n",
      "Processing vizamyl...\n",
      "Processing gazyva...\n",
      "Processing aptiom...\n",
      "Processing imbruvica...\n",
      "Processing luzu...\n",
      "Processing olysio...\n",
      "Processing sovaldi...\n",
      "Processing anoro-ellipta...\n",
      "Processing farxiga...\n",
      "Processing hetlioz...\n",
      "Processing vimizim...\n",
      "Processing northera...\n",
      "Processing myalept...\n",
      "Processing impavido...\n",
      "Processing neuraceq...\n",
      "Processing otezla...\n",
      "Processing tanzeum...\n",
      "Processing cyramza...\n",
      "Processing sylvant...\n",
      "Processing zykadia...\n",
      "Processing zontivity...\n",
      "Processing entyvio...\n",
      "Processing dalvance...\n",
      "Processing jublia...\n",
      "Processing sivextro...\n",
      "Processing beleodaq...\n",
      "Processing kerydin...\n",
      "Processing zydelig...\n",
      "Processing striverdi-respimat...\n",
      "Processing jardiance...\n",
      "Processing orbactiv...\n",
      "Processing belsomra...\n",
      "Processing plegridy...\n",
      "Processing cerdelga...\n",
      "Processing keytruda...\n",
      "Processing movantik...\n",
      "Processing trulicity...\n",
      "Processing akynzeo...\n",
      "Processing lumason...\n",
      "Processing harvoni...\n",
      "Processing esbriet...\n",
      "Processing ofev...\n",
      "Processing blincyto...\n",
      "Processing xtoro...\n",
      "Processing lynparza...\n",
      "Processing zerbaxa...\n",
      "Processing rapivab...\n",
      "Processing viekira-pak...\n",
      "Processing opdivo...\n",
      "Processing savaysa...\n",
      "Processing cosentyx...\n",
      "Processing natpara...\n",
      "Processing ibrance...\n",
      "Processing lenvima...\n",
      "Processing farydak...\n",
      "Processing avycaz...\n",
      "Processing cresemba...\n",
      "Processing unituxin...\n",
      "Processing cholbam...\n",
      "Processing corlanor...\n",
      "Processing kybella...\n",
      "Processing viberzi...\n",
      "Processing kengreal...\n",
      "Processing orkambi...\n",
      "Processing entresto...\n",
      "Processing rexulti...\n",
      "Processing odomzo...\n",
      "Processing praluent...\n",
      "Processing daklinza...\n",
      "Processing addyi...\n",
      "Processing repatha...\n",
      "Processing varubi...\n",
      "Processing xuriden...\n",
      "Processing vraylar...\n",
      "Processing lonsurf...\n",
      "Processing tresiba...\n",
      "Processing aristada...\n",
      "Processing praxbind...\n",
      "Processing veltassa...\n",
      "Processing strensiq...\n",
      "Processing yondelis...\n",
      "Processing nucala...\n",
      "Processing genvoya...\n",
      "Processing cotellic...\n",
      "Processing tagrisso...\n",
      "Processing darzalex...\n",
      "Processing ninlaro...\n",
      "Processing portrazza...\n",
      "Processing empliciti...\n",
      "Processing kanuma...\n",
      "Processing alecensa...\n",
      "Processing bridion...\n",
      "Processing uptravi...\n",
      "Processing zurampic...\n",
      "Processing zepatier...\n",
      "Processing briviact...\n",
      "Processing anthim...\n",
      "Processing taltz...\n",
      "Processing cinqair...\n",
      "Processing defitelio...\n",
      "Processing venclexta...\n",
      "Processing nuplazid...\n",
      "Processing tecentriq...\n",
      "Processing zinbryta...\n",
      "Processing axumin...\n",
      "Processing ocaliva...\n",
      "Processing netspot...\n",
      "Processing epclusa...\n",
      "Processing xiidra...\n",
      "Processing adlyxin...\n",
      "Processing exondys-51...\n",
      "Processing lartruvo...\n",
      "Processing zinplava...\n",
      "Processing eucrisa...\n",
      "Processing rubraca...\n",
      "Processing spinraza...\n",
      "Processing trulance...\n",
      "Processing parsabiv...\n",
      "Processing emflaza...\n",
      "Processing siliq...\n",
      "Processing xermelo...\n",
      "Processing kisqali...\n",
      "Processing xadago...\n",
      "Processing bavencio...\n",
      "Processing symproic...\n",
      "Processing zejula...\n",
      "Processing ocrevus...\n",
      "Processing dupixent...\n",
      "Processing austedo...\n",
      "Processing ingrezza...\n",
      "Processing brineura...\n",
      "Processing rydapt...\n",
      "Processing tymlos...\n",
      "Processing alunbrig...\n",
      "Processing imfinzi...\n",
      "Processing radicava...\n",
      "Processing kevzara...\n",
      "Processing baxdela...\n",
      "Processing bevyxxa...\n",
      "Processing tremfya...\n",
      "Processing nerlynx...\n",
      "Processing vosevi...\n",
      "Processing idhifa...\n",
      "Processing mavyret...\n",
      "Processing besponsa...\n",
      "Processing vabomere...\n",
      "Processing aliqopa...\n",
      "Processing solosec...\n",
      "Processing verzenio...\n",
      "Processing calquence...\n",
      "Processing vyzulta...\n",
      "Processing prevymis...\n",
      "Processing fasenra...\n",
      "Processing mepsevii...\n",
      "Processing hemlibra...\n",
      "Processing ozempic...\n",
      "Processing xepi...\n",
      "Processing rhopressa...\n",
      "Processing steglatro...\n",
      "Processing macrilen...\n",
      "Processing giapreza...\n",
      "Processing lutathera...\n",
      "Processing biktarvy...\n",
      "Processing symdeko...\n",
      "Processing erleada...\n",
      "Processing trogarzo...\n",
      "Processing ilumya...\n",
      "Processing crysvita...\n",
      "Processing tavalisse...\n",
      "Processing lucemyra...\n",
      "Processing aimovig...\n",
      "Processing lokelma...\n",
      "Processing doptelet...\n",
      "Processing palynziq...\n",
      "Processing olumiant...\n",
      "Processing zemdri...\n",
      "Processing epidiolex...\n",
      "Processing braftovi...\n",
      "Processing mektovi...\n",
      "Processing tpoxx...\n",
      "Processing krintafel...\n",
      "Processing tibsovo...\n",
      "Processing orilissa...\n",
      "Processing omegaven...\n",
      "Processing mulpleta...\n",
      "Processing poteligeo...\n",
      "Processing galafold...\n",
      "Processing annovera...\n",
      "Processing onpattro...\n",
      "Processing diacomit...\n",
      "Processing oxervate...\n",
      "Processing takhzyro...\n",
      "Processing xerava...\n",
      "Processing pifeltro...\n",
      "Processing lumoxiti...\n",
      "Processing ajovy...\n",
      "Processing copiktra...\n",
      "Processing emgality...\n",
      "Processing vizimpro...\n",
      "Processing libtayo...\n",
      "Processing seysara...\n",
      "Processing nuzyra...\n",
      "Processing revcovi...\n",
      "Processing tegsedi...\n",
      "Processing talzenna...\n",
      "Processing xofluza...\n",
      "Processing lorbrena...\n",
      "Processing yupelri...\n",
      "Processing aemcolo...\n",
      "Processing gamifant...\n",
      "Processing daurismo...\n",
      "Processing vitrakvi...\n",
      "Processing firdapse...\n",
      "Processing xospata...\n",
      "Processing motegrity...\n",
      "Processing asparlas...\n",
      "Processing ultomiris...\n",
      "Processing elzonris...\n",
      "Processing jeuveau...\n",
      "Processing cablivi...\n",
      "Processing egaten...\n",
      "Processing zulresso...\n",
      "Processing sunosi...\n",
      "Processing mayzent...\n",
      "Processing evenity...\n",
      "Processing balversa...\n",
      "Processing skyrizi...\n",
      "Processing vyndaqel...\n",
      "Processing piqray...\n",
      "Processing polivy...\n",
      "Processing vyleesi...\n",
      "Processing xpovio...\n",
      "Processing recarbrio...\n",
      "Processing accrufer...\n",
      "Processing nubeqa...\n",
      "Processing turalio...\n",
      "Processing wakix...\n",
      "Processing rozlytrek...\n",
      "Processing inrebic...\n",
      "Processing rinvoq...\n",
      "Processing xenleta...\n",
      "Processing nourianz...\n",
      "Processing ibsrela...\n",
      "Processing aklief...\n",
      "Processing beovu...\n",
      "Processing scenesse...\n",
      "Processing reyvow...\n",
      "Processing trikafta...\n",
      "Processing exem-foam...\n",
      "Processing reblozyl...\n",
      "Processing brukinsa...\n",
      "Processing fetroja...\n",
      "Processing adakveo...\n",
      "Processing givlaari...\n",
      "Processing xcopri...\n",
      "Processing oxbryta...\n",
      "Processing vyondys-53...\n",
      "Processing padcev...\n",
      "Processing caplyta...\n",
      "Processing enhertu...\n",
      "Processing tissueblue...\n",
      "Processing dayvigo...\n",
      "Processing ubrelvy...\n",
      "Processing ayvakit...\n",
      "Processing tepezza...\n",
      "Processing tazverik...\n",
      "Processing pizensy...\n",
      "Processing nexletol...\n",
      "Processing vyepti...\n",
      "Processing barhemsys...\n",
      "Processing nurtec-odt...\n",
      "Processing sarclisa...\n",
      "Processing isturisa...\n",
      "Processing zeposia...\n",
      "Processing koselugo...\n",
      "Processing pemazyre...\n",
      "Processing tukysa...\n",
      "Processing trodelvy...\n",
      "Processing ongentys...\n",
      "Processing tabrecta...\n",
      "Processing retevmo...\n",
      "Processing qinlock...\n",
      "Processing cerianna...\n",
      "Processing tauvid...\n",
      "Processing uplizna...\n",
      "Processing zepzelca...\n",
      "Processing dojolvi...\n",
      "Processing byfavo...\n",
      "Processing rukobia...\n",
      "Processing inqovi...\n",
      "Processing xeglyze...\n",
      "Processing monjuvi...\n",
      "Processing blenrep...\n",
      "Processing lampit...\n",
      "Processing evrysdi...\n",
      "Processing olinvyk...\n",
      "Processing viltepso...\n",
      "Processing enspryng...\n",
      "Processing winlevi...\n",
      "Processing sogroya...\n",
      "Processing detectnet...\n",
      "Processing gavreto...\n",
      "Processing inmazeb...\n",
      "Processing veklury...\n",
      "Processing zokinvy...\n",
      "Processing oxlumo...\n",
      "Processing imcivree...\n",
      "Processing danyelza...\n",
      "Processing orladeyo...\n",
      "Processing klisyri...\n",
      "Processing margenza...\n",
      "Processing orgovyx...\n",
      "Processing ebanga...\n",
      "Processing gemtesa...\n",
      "Processing verquvo...\n",
      "Processing cabenuva...\n",
      "Processing lupkynis...\n",
      "Processing tepmetko...\n",
      "Processing ukoniq...\n",
      "Processing evkeeza...\n",
      "Processing cosela...\n",
      "Processing amondys-45...\n",
      "Processing nulibry...\n",
      "Processing pepaxto...\n",
      "Processing azstarys...\n",
      "Processing fotivda...\n",
      "Processing ponvory...\n",
      "Processing zegalogue...\n",
      "Processing qelbree...\n",
      "Processing nextstellis...\n",
      "Processing jemperli...\n",
      "Processing zynlonta...\n",
      "Processing empaveli...\n",
      "Processing rybrevant...\n",
      "Processing pylarify...\n",
      "Processing lumakras...\n",
      "Processing lybalvi...\n",
      "Processing truseltiq...\n",
      "Processing brexafemme...\n",
      "Processing aduhelm...\n",
      "Processing rylaze...\n",
      "Processing kerendia...\n",
      "Processing rezurock...\n",
      "Processing bylvay...\n",
      "Processing saphnelo...\n",
      "Processing nexviazyme...\n",
      "Processing welireg...\n",
      "Processing korsuva...\n",
      "Processing skytrofa...\n",
      "Processing exkivity...\n",
      "Processing tivdak...\n",
      "Processing qulipta...\n",
      "Processing livmarli...\n",
      "Processing tavneos...\n",
      "Processing scemblix...\n",
      "Processing besremi...\n",
      "Processing voxzogo...\n",
      "Processing livtencity...\n",
      "Processing cytalux...\n",
      "Processing tezspire...\n",
      "Processing vyvgart...\n",
      "Processing leqvio...\n",
      "Processing adbry...\n",
      "Processing quviviq...\n",
      "Processing cibinqo...\n",
      "Processing kimmtrak...\n",
      "Processing vabysmo...\n",
      "Processing enjaymo...\n",
      "Processing pyrukynd...\n",
      "Processing vonjo...\n",
      "Processing opdualag...\n",
      "Processing ztalmy...\n",
      "Processing pluvicto...\n",
      "Processing vivjoa...\n",
      "Processing camzyos...\n",
      "Processing voquezna-triple-pak...\n",
      "Processing mounjaro...\n",
      "Processing vtama...\n",
      "Processing amvuttra...\n",
      "Processing xenpozyme...\n",
      "Processing spevigo...\n",
      "Processing daxxify...\n",
      "Processing rolvedon...\n",
      "Processing sotyktu...\n",
      "Processing terlivaz...\n",
      "Processing elucirem...\n",
      "Processing omlonti...\n",
      "Processing relyvrio...\n",
      "Processing lytgobi...\n",
      "Processing imjudo...\n",
      "Processing tecvayli...\n",
      "Processing elahere...\n",
      "Processing tzield...\n",
      "Processing rezlidhia...\n",
      "Processing krazati...\n",
      "Processing lunsumio...\n",
      "Processing sunlenca...\n",
      "Processing xenoview...\n",
      "Processing briumvi...\n",
      "Processing nexobrid...\n",
      "Processing leqembi...\n",
      "Processing brenzavvy...\n",
      "Processing jaypirca...\n",
      "Processing orserdu...\n",
      "Processing jesduvroq...\n",
      "Processing lamzede...\n",
      "Processing filspari...\n",
      "Processing skyclarys...\n",
      "Processing zavzpret...\n",
      "Processing daybue...\n",
      "Processing rezzayo...\n",
      "Processing zynyz...\n",
      "Processing joenja...\n",
      "Processing qalsody...\n",
      "Processing elfabrio...\n",
      "Processing veozah...\n",
      "Processing miebo...\n",
      "Processing epkinly...\n",
      "Processing xacduro...\n",
      "Processing posluma...\n",
      "Processing paxlovid...\n",
      "Processing inpefa...\n",
      "Processing columvi...\n",
      "Processing litfulo...\n",
      "Processing rystiggo...\n",
      "Processing ngenla...\n",
      "Processing beyfortus...\n",
      "Processing vanflyta...\n",
      "Processing xdemvy...\n",
      "Processing izervay...\n",
      "Processing zurzuvae...\n",
      "Processing talvey...\n",
      "Processing elrexfio...\n",
      "Processing sohonos...\n",
      "Processing veopoz...\n",
      "Processing aphexda...\n",
      "Processing ojjaara...\n",
      "Processing exxua...\n",
      "Processing pombiliti...\n",
      "Processing rivfloza...\n",
      "Processing velsipity...\n",
      "Processing zilbrysq...\n",
      "Processing bimzelx...\n",
      "Processing agamree...\n",
      "Processing omvoh...\n",
      "Processing loqtorzi...\n",
      "Processing fruzaqla...\n",
      "Processing defencath...\n",
      "Processing augtyro...\n",
      "Processing truqap...\n",
      "Processing ryzneuta...\n",
      "Processing ogsiveo...\n",
      "Processing fabhalta...\n",
      "Processing filsuvez...\n",
      "Processing wainua...\n",
      "\n",
      "✅ Done! Data saved to: F:\\PhD\\RA\\Schafer\\IRA\\data\\nme\\all_drugs_approval_entries.xlsx\n",
      "Skipped drug list saved to: F:\\PhD\\RA\\Schafer\\IRA\\data\\nme\\skipped_drugs.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "input_path = r\"F:\\PhD\\RA\\Schafer\\IRA\\data\\nme\\nme_approved_2000onward.xlsx\"\n",
    "df = pd.read_excel(input_path)\n",
    "drugnames = df['drugname'].dropna().str.strip().str.lower().str.replace(' ', '-').unique().tolist()\n",
    "\n",
    "all_rows = []\n",
    "skipped_drugs = []\n",
    "\n",
    "for drugname in drugnames:\n",
    "    url = f\"https://www.drugs.com/history/{drugname}.html\"\n",
    "    print(f\"Processing {drugname}...\")\n",
    "    try:\n",
    "        response = requests.get(url, timeout=30)\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        table = soup.find(\"table\")\n",
    "        found = False\n",
    "        if table:\n",
    "            for tr in table.find_all(\"tr\"):\n",
    "                tds = tr.find_all(\"td\")\n",
    "                if len(tds) >= 2:\n",
    "                    date = tds[0].get_text(strip=True)\n",
    "                    details = tds[1].get_text(strip=True)\n",
    "                    if details.lower().startswith(\"approval\"):\n",
    "                        all_rows.append({\n",
    "                            \"drugname\": drugname,\n",
    "                            \"date\": date,\n",
    "                            \"details\": details,\n",
    "                            \"url\": url\n",
    "                        })\n",
    "                        found = True\n",
    "        # Mark as skipped if no approvals were found\n",
    "        if not found:\n",
    "            all_rows.append({\n",
    "                \"drugname\": drugname,\n",
    "                \"date\": None,\n",
    "                \"details\": \"SKIPPED_OR_NOT_FOUND\",\n",
    "                \"url\": url\n",
    "            })\n",
    "            skipped_drugs.append(drugname)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {drugname}: {e}\")\n",
    "        all_rows.append({\n",
    "            \"drugname\": drugname,\n",
    "            \"date\": None,\n",
    "            \"details\": f\"SKIPPED_OR_ERROR: {e}\",\n",
    "            \"url\": url\n",
    "        })\n",
    "        skipped_drugs.append(drugname)\n",
    "    time.sleep(0.5)\n",
    "\n",
    "df_all = pd.DataFrame(all_rows)\n",
    "output_path = r\"F:\\PhD\\RA\\Schafer\\IRA\\data\\nme\\all_drugs_approval_entries.xlsx\"\n",
    "df_all.to_excel(output_path, index=False)\n",
    "print(f\"\\n✅ Done! Data saved to: {output_path}\")\n",
    "\n",
    "# Save the skipped list for re-processing or manual review\n",
    "skipped_path = r\"F:\\PhD\\RA\\Schafer\\IRA\\data\\nme\\skipped_drugs.csv\"\n",
    "pd.Series(skipped_drugs, name=\"drugname\").to_csv(skipped_path, index=False)\n",
    "print(f\"Skipped drug list saved to: {skipped_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b4bcba1a-d80a-49bd-bdf9-2822c8314d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrying evoxac...\n",
      "Retrying trileptal...\n",
      "Retrying protonix...\n",
      "Retrying lotronex...\n",
      "Retrying skin-exposure-reduction-paste-against-chemical-warfare-agents-(serpacwa)...\n",
      "Retrying zonegran...\n",
      "Retrying septocaine...\n",
      "Retrying visudyne...\n",
      "Retrying mobic...\n",
      "Retrying zyvox...\n",
      "Retrying lantus...\n",
      "Retrying exelon...\n",
      "Retrying welchol...\n",
      "Retrying novolog...\n",
      "Retrying trelstar-depot...\n",
      "Retrying acova...\n",
      "Retrying innohep...\n",
      "Retrying colazal...\n",
      "Retrying abreva...\n",
      "Retrying rescula...\n",
      "Retrying cetrotide...\n",
      "Retrying kaletra...\n",
      "Retrying trisenox...\n",
      "Retrying mifeprex...\n",
      "Retrying angiomax...\n",
      "Retrying starlix...\n",
      "Retrying peg-intron...\n",
      "Retrying cancidas...\n",
      "Retrying geodon...\n",
      "Retrying foradil...\n",
      "Retrying reminyl...\n",
      "Retrying travatan...\n",
      "Retrying lumigan...\n",
      "Retrying campath...\n",
      "Retrying axert...\n",
      "Retrying yasmin...\n",
      "Retrying natrecor...\n",
      "Retrying zometa...\n",
      "Retrying spectracef...\n",
      "Retrying aranesp...\n",
      "Retrying nuvaring...\n",
      "Retrying viread...\n",
      "Retrying frova...\n",
      "Retrying bextra...\n",
      "Retrying avodart...\n",
      "Retrying ortho-evra...\n",
      "Retrying tracleer...\n",
      "Retrying invanz...\n",
      "Retrying xigris...\n",
      "Retrying arixtra...\n",
      "Retrying elidel...\n",
      "Retrying clarinex...\n",
      "Retrying orfadin...\n",
      "Retrying neulasta...\n",
      "Retrying zevalin...\n",
      "Retrying rebif...\n",
      "Retrying benicar...\n",
      "Retrying remodulin...\n",
      "Retrying vfend...\n",
      "Retrying imagent...\n",
      "Retrying elitek...\n",
      "Retrying xyrem...\n",
      "Retrying hepsera...\n",
      "Retrying inspra...\n",
      "Retrying pegasys...\n",
      "Retrying zetia...\n",
      "Retrying abilify...\n",
      "Retrying strattera...\n",
      "Retrying extraneal...\n",
      "Retrying relpax...\n",
      "Retrying amevive...\n",
      "Retrying fuzeon...\n",
      "Retrying somavert...\n",
      "Retrying emend...\n",
      "Retrying factive...\n",
      "Retrying fabrazyme...\n",
      "Retrying aldurazyme...\n",
      "Retrying boniva...\n",
      "Retrying uroxatral...\n",
      "Retrying reyataz...\n",
      "Retrying bexxar...\n",
      "Retrying emtriva...\n",
      "Retrying aloxi...\n",
      "Retrying zavesca...\n",
      "Retrying crestor...\n",
      "Retrying levitra...\n",
      "Retrying cubicin...\n",
      "Retrying radiogardase...\n",
      "Retrying elestat...\n",
      "Retrying namenda...\n",
      "Retrying raptiva...\n",
      "Retrying plenaxis...\n",
      "Retrying ertaczo...\n",
      "Retrying ketek...\n",
      "Retrying nutrestore...\n",
      "Retrying neutrospec...\n",
      "Retrying [drug-marketed-without-a-proprietary-name]...\n",
      "Retrying multihance...\n",
      "Retrying visionblue...\n",
      "Retrying hydase...\n",
      "Retrying chantix...\n",
      "Retrying anthelios-sx...\n",
      "Retrying arcapta-neohaler...\n",
      "Retrying omegaven...\n",
      "Retrying exem-foam...\n",
      "Retrying tissueblue...\n",
      "\n",
      "✅ Combined data saved to: F:\\PhD\\RA\\Schafer\\IRA\\data\\nme\\all_drugs_approval_entries_combined.xlsx\n",
      "⛔️ Still-skipped drug list saved to: F:\\PhD\\RA\\Schafer\\IRA\\data\\nme\\still_skipped_drugs.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "skipped_path = r\"F:\\PhD\\RA\\Schafer\\IRA\\data\\nme\\skipped_drugs.csv\"\n",
    "skipped_drugs = pd.read_csv(skipped_path)['drugname'].tolist()\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "retry_rows = []\n",
    "still_skipped = []\n",
    "\n",
    "for drugname in skipped_drugs:\n",
    "    url = f\"https://www.drugs.com/history/{drugname}.html\"\n",
    "    print(f\"Retrying {drugname}...\")\n",
    "    try:\n",
    "        response = requests.get(url, timeout=30)\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        table = soup.find(\"table\")\n",
    "        found = False\n",
    "        if table:\n",
    "            for tr in table.find_all(\"tr\"):\n",
    "                tds = tr.find_all(\"td\")\n",
    "                if len(tds) >= 2:\n",
    "                    date = tds[0].get_text(strip=True)\n",
    "                    details = tds[1].get_text(strip=True)\n",
    "                    if details.lower().startswith(\"approval\"):\n",
    "                        retry_rows.append({\n",
    "                            \"drugname\": drugname,\n",
    "                            \"date\": date,\n",
    "                            \"details\": details,\n",
    "                            \"url\": url\n",
    "                        })\n",
    "                        found = True\n",
    "        if not found:\n",
    "            retry_rows.append({\n",
    "                \"drugname\": drugname,\n",
    "                \"date\": None,\n",
    "                \"details\": \"STILL_SKIPPED_OR_NOT_FOUND\",\n",
    "                \"url\": url\n",
    "            })\n",
    "            still_skipped.append(drugname)\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrying {drugname}: {e}\")\n",
    "        retry_rows.append({\n",
    "            \"drugname\": drugname,\n",
    "            \"date\": None,\n",
    "            \"details\": f\"STILL_SKIPPED_OR_ERROR: {e}\",\n",
    "            \"url\": url\n",
    "        })\n",
    "        still_skipped.append(drugname)\n",
    "    time.sleep(0.5)\n",
    "\n",
    "df_retry = pd.DataFrame(retry_rows)\n",
    "\n",
    "# Load your first run results\n",
    "df_all = pd.read_excel(r\"F:\\PhD\\RA\\Schafer\\IRA\\data\\nme\\all_drugs_approval_entries.xlsx\")\n",
    "\n",
    "# Drop the old skipped rows before appending retry results\n",
    "df_success = df_all[~df_all['drugname'].isin(skipped_drugs)].copy()\n",
    "\n",
    "# Only keep retries that were successful (not skipped again)\n",
    "df_retry_success = df_retry[~df_retry['details'].str.contains(\"SKIPPED|NOT FOUND|ERROR\", case=False, na=False)].copy()\n",
    "\n",
    "# Combine the original successful and new retry successes\n",
    "df_final = pd.concat([df_success, df_retry_success], ignore_index=True)\n",
    "\n",
    "# Save all results\n",
    "final_output_path = r\"F:\\PhD\\RA\\Schafer\\IRA\\data\\nme\\all_drugs_approval_entries_combined.xlsx\"\n",
    "df_final.to_excel(final_output_path, index=False)\n",
    "print(f\"\\n✅ Combined data saved to: {final_output_path}\")\n",
    "\n",
    "# Save the still-skipped list for review or manual check\n",
    "still_skipped_path = r\"F:\\PhD\\RA\\Schafer\\IRA\\data\\nme\\still_skipped_drugs.csv\"\n",
    "pd.Series(still_skipped, name=\"drugname\").to_csv(still_skipped_path, index=False)\n",
    "print(f\"⛔️ Still-skipped drug list saved to: {still_skipped_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "249f96b2-73d8-4e01-bdb5-b5fe20797b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  date date_clean date_parsed\n",
      "0  NaN        NaN         NaT\n",
      "1  NaN        NaN         NaT\n",
      "2  NaN        NaN         NaT\n",
      "3  NaN        NaN         NaT\n",
      "4  NaN        NaN         NaT\n",
      "✅ Done! Merged data saved to: F:\\PhD\\RA\\Schafer\\IRA\\data\\nme\\nme_fda_merged_with_approvals.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load FDA base sheet\n",
    "fda_path = r\"F:\\PhD\\RA\\Schafer\\IRA\\data\\nme\\nme_approved_2020onward.xlsx\"\n",
    "df_fda = pd.read_excel(fda_path)\n",
    "\n",
    "# Load all approvals (combined after retry)\n",
    "combined_path = r\"F:\\PhD\\RA\\Schafer\\IRA\\data\\nme\\all_drugs_approval_entries_combined.xlsx\"\n",
    "df_approvals = pd.read_excel(combined_path)\n",
    "\n",
    "# Clean drug names for merge (lowercase, strip, replace space with hyphen)\n",
    "df_fda['drugname_clean'] = df_fda['drugname'].str.strip().str.lower().str.replace(' ', '-')\n",
    "df_approvals['drugname_clean'] = df_approvals['drugname'].str.strip().str.lower()\n",
    "\n",
    "# Merge, keeping all FDA rows, and add approvals where found\n",
    "df_merged = pd.merge(\n",
    "    df_fda,\n",
    "    df_approvals[['drugname_clean', 'date', 'details', 'url']],\n",
    "    on='drugname_clean',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# (Optional) Drop the helper column for output\n",
    "df_merged = df_merged.drop(columns=['drugname_clean'])\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Assuming df_merged is your DataFrame and the column is called \"date\"\n",
    "def clean_date(s):\n",
    "    if pd.isna(s):\n",
    "        return s\n",
    "    # Replace multiple spaces with a single space\n",
    "    s = re.sub(r'\\s+', ' ', s.strip())\n",
    "    return s\n",
    "\n",
    "df_merged['date_clean'] = df_merged['date'].apply(clean_date)\n",
    "# Now convert to datetime (this will coerce invalid formats to NaT)\n",
    "df_merged['date_parsed'] = pd.to_datetime(df_merged['date_clean'], errors='coerce')\n",
    "\n",
    "# Preview result\n",
    "print(df_merged[['date', 'date_clean', 'date_parsed']].head())\n",
    "df_merged['date'] = df_merged['date'].apply(clean_date)\n",
    "df_merged['date'] = pd.to_datetime(df_merged['date'], errors='coerce')\n",
    "\n",
    "# Save to Excel\n",
    "merged_path = r\"F:\\PhD\\RA\\Schafer\\IRA\\data\\nme\\nme_fda_merged_with_approvals.xlsx\"\n",
    "df_merged.to_excel(merged_path, index=False)\n",
    "print(f\"✅ Done! Merged data saved to: {merged_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e75361c7-8150-420d-856f-441f97b8179b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved clean file to: F:\\PhD\\RA\\Schafer\\IRA\\data\\nme\\nme_fda_merged_with_approvals_clean.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load FDA base sheet\n",
    "fda_path = r\"F:\\PhD\\RA\\Schafer\\IRA\\data\\nme\\nme_fda_merged_with_approvals.xlsx\"\n",
    "df = pd.read_excel(fda_path)\n",
    "\n",
    "# Convert both columns to datetime (if not already)\n",
    "df['FDA Approval Date'] = pd.to_datetime(df['FDA Approval Date'], errors='coerce')\n",
    "df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "\n",
    "# Keep only the date part (as a string, so Excel shows YYYY-MM-DD)\n",
    "df['FDA Approval Date'] = df['FDA Approval Date'].dt.date\n",
    "df['date'] = df['date'].dt.date\n",
    "\n",
    "# Drop rows with empty or missing details\n",
    "df = df[df['details'].notna() & (df['details'].str.strip() != '')].copy()\n",
    "\n",
    "# Drop only rows where details starts with \"Approval \" (with a space)\n",
    "mask = df['details'].str.match(r'^Approval\\s', na=False)\n",
    "df = df[~mask].copy()\n",
    "\n",
    "# Save to Excel\n",
    "output_path = r\"F:\\PhD\\RA\\Schafer\\IRA\\data\\nme\\nme_fda_merged_with_approvals_clean.xlsx\"\n",
    "df.to_excel(output_path, index=False)\n",
    "print(f\"✅ Saved clean file to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c91201-603a-4386-925e-f0e0021e1562",
   "metadata": {},
   "source": [
    "## Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e71099d2-d2bc-4a65-bbda-519a0d533eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing keytruda...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'drugname_clean'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[61], line 65\u001b[0m\n\u001b[0;32m     62\u001b[0m df_all\u001b[38;5;241m.\u001b[39mto_excel(output_path, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Merge with your original DataFrame to get FDA Approval Date and pretty drugname\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m df_all \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(\n\u001b[0;32m     66\u001b[0m     df_all,\n\u001b[0;32m     67\u001b[0m     df_filtered[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdrugname_clean\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdrugname\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFDA Approval Date\u001b[39m\u001b[38;5;124m'\u001b[39m]],\n\u001b[0;32m     68\u001b[0m     on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdrugname_clean\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     69\u001b[0m     how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     70\u001b[0m )\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_all\u001b[38;5;241m.\u001b[39mhead())\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal records:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(df_all))\n",
      "File \u001b[1;32mD:\\anaconda\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:170\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _cross_merge(\n\u001b[0;32m    156\u001b[0m         left_df,\n\u001b[0;32m    157\u001b[0m         right_df,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    167\u001b[0m         copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    168\u001b[0m     )\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 170\u001b[0m     op \u001b[38;5;241m=\u001b[39m _MergeOperation(\n\u001b[0;32m    171\u001b[0m         left_df,\n\u001b[0;32m    172\u001b[0m         right_df,\n\u001b[0;32m    173\u001b[0m         how\u001b[38;5;241m=\u001b[39mhow,\n\u001b[0;32m    174\u001b[0m         on\u001b[38;5;241m=\u001b[39mon,\n\u001b[0;32m    175\u001b[0m         left_on\u001b[38;5;241m=\u001b[39mleft_on,\n\u001b[0;32m    176\u001b[0m         right_on\u001b[38;5;241m=\u001b[39mright_on,\n\u001b[0;32m    177\u001b[0m         left_index\u001b[38;5;241m=\u001b[39mleft_index,\n\u001b[0;32m    178\u001b[0m         right_index\u001b[38;5;241m=\u001b[39mright_index,\n\u001b[0;32m    179\u001b[0m         sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m    180\u001b[0m         suffixes\u001b[38;5;241m=\u001b[39msuffixes,\n\u001b[0;32m    181\u001b[0m         indicator\u001b[38;5;241m=\u001b[39mindicator,\n\u001b[0;32m    182\u001b[0m         validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[0;32m    183\u001b[0m     )\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result(copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[1;32mD:\\anaconda\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:794\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MergeError(msg)\n\u001b[0;32m    786\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_on, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_on \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_left_right_on(left_on, right_on)\n\u001b[0;32m    788\u001b[0m (\n\u001b[0;32m    789\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_join_keys,\n\u001b[0;32m    790\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_join_keys,\n\u001b[0;32m    791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjoin_names,\n\u001b[0;32m    792\u001b[0m     left_drop,\n\u001b[0;32m    793\u001b[0m     right_drop,\n\u001b[1;32m--> 794\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_merge_keys()\n\u001b[0;32m    796\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m left_drop:\n\u001b[0;32m    797\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft\u001b[38;5;241m.\u001b[39m_drop_labels_or_levels(left_drop)\n",
      "File \u001b[1;32mD:\\anaconda\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:1310\u001b[0m, in \u001b[0;36m_MergeOperation._get_merge_keys\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lk \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1307\u001b[0m     \u001b[38;5;66;03m# Then we're either Hashable or a wrong-length arraylike,\u001b[39;00m\n\u001b[0;32m   1308\u001b[0m     \u001b[38;5;66;03m#  the latter of which will raise\u001b[39;00m\n\u001b[0;32m   1309\u001b[0m     lk \u001b[38;5;241m=\u001b[39m cast(Hashable, lk)\n\u001b[1;32m-> 1310\u001b[0m     left_keys\u001b[38;5;241m.\u001b[39mappend(left\u001b[38;5;241m.\u001b[39m_get_label_or_level_values(lk))\n\u001b[0;32m   1311\u001b[0m     join_names\u001b[38;5;241m.\u001b[39mappend(lk)\n\u001b[0;32m   1312\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1313\u001b[0m     \u001b[38;5;66;03m# work-around for merge_asof(left_index=True)\u001b[39;00m\n",
      "File \u001b[1;32mD:\\anaconda\\Lib\\site-packages\\pandas\\core\\generic.py:1911\u001b[0m, in \u001b[0;36mNDFrame._get_label_or_level_values\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1909\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\u001b[38;5;241m.\u001b[39mget_level_values(key)\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m   1910\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1911\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[0;32m   1913\u001b[0m \u001b[38;5;66;03m# Check for duplicates\u001b[39;00m\n\u001b[0;32m   1914\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m values\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'drugname_clean'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Path to your filtered Excel with 'drugname'\n",
    "input_path = r\"F:\\PhD\\RA\\Schafer\\IRA\\data\\nme\\nme_approved_2020onward.xlsx\"  # update if needed\n",
    "\n",
    "# Read in your DataFrame with the 'drugname' column\n",
    "df_filtered = pd.read_excel(input_path)\n",
    "\n",
    "# Clean up drug names for use in URL (lowercase, strip spaces, replace spaces with '-')\n",
    "df_filtered['drugname_clean'] = df_filtered['drugname'].str.strip().str.lower().str.replace(' ', '-')\n",
    "drugnames = ['keytruda']\n",
    "\n",
    "all_rows = []\n",
    "\n",
    "for drugname in drugnames:\n",
    "    url = f\"https://www.drugs.com/history/{drugname}.html\"\n",
    "    print(f\"Processing {drugname}...\")\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        table = soup.find(\"table\")\n",
    "        found = False\n",
    "        if table:\n",
    "            for tr in table.find_all(\"tr\"):\n",
    "                tds = tr.find_all(\"td\")\n",
    "                if len(tds) >= 2:\n",
    "                    date = tds[0].get_text(strip=True)\n",
    "                    details = tds[1].get_text(strip=True)\n",
    "                    # Only rows starting with \"Approval\"\n",
    "                    if details.lower().startswith(\"approval\"):\n",
    "                        all_rows.append({\n",
    "                            \"drugname\": drugname,\n",
    "                            \"date\": date,\n",
    "                            \"details\": details,\n",
    "                            \"url\": url\n",
    "                        })\n",
    "                        found = True\n",
    "        if not found:\n",
    "            for entry in soup.find_all(\"li\", class_=\"ddc-history-event\"):\n",
    "                label = entry.find(\"span\", class_=\"label\")\n",
    "                if label and \"Approval\" in label.text:\n",
    "                    date = entry.find(\"span\", class_=\"date\").text.strip()\n",
    "                    article = entry.find(\"span\", class_=\"title\").text.strip()\n",
    "                    if article.lower().startswith(\"approval\"):\n",
    "                        all_rows.append({\n",
    "                            \"drugname\": drugname,\n",
    "                            \"date\": date,\n",
    "                            \"details\": article,\n",
    "                            \"url\": url\n",
    "                        })\n",
    "        time.sleep(0.5)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {drugname}: {e}\")\n",
    "\n",
    "# Create DataFrame, merge back to original for pretty names and approval dates\n",
    "df_all = pd.DataFrame(all_rows)\n",
    "\n",
    "output_path = r\"F:\\PhD\\RA\\Schafer\\IRA\\data\\nme\\all_drugs_approval_entries.xlsx\"\n",
    "df_all.to_excel(output_path, index=False)\n",
    "\n",
    "# Merge with your original DataFrame to get FDA Approval Date and pretty drugname\n",
    "df_all = pd.merge(\n",
    "    df_all,\n",
    "    df_filtered[['drugname_clean', 'drugname', 'FDA Approval Date']],\n",
    "    on='drugname_clean',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(df_all.head())\n",
    "print(\"Total records:\", len(df_all))\n",
    "\n",
    "# Save to Excel\n",
    "output_path = r\"F:\\PhD\\RA\\Schafer\\IRA\\data\\nme\\all_drugs_approval_entries.xlsx\"\n",
    "df_all.to_excel(output_path, index=False)\n",
    "print(f\"\\n✅ Done! Data saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "03280ec5-94b6-4dc0-b2fd-156423279f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    drugname          date                                            details  \\\n",
      "0   keytruda  Mar 19, 2025  ApprovalFDA Approves Pembrolizumab for HER2 Po...   \n",
      "1   keytruda  Sep 18, 2024  ApprovalFDA Approves Merck’s Keytruda (pembrol...   \n",
      "2   keytruda  Jul  9, 2024  Approval for the First Dose Cohort in Phase 1a...   \n",
      "3   keytruda  Jun 17, 2024  ApprovalFDA Approves Merck’s Keytruda (pembrol...   \n",
      "4   keytruda  Jan 12, 2024  ApprovalFDA Approves Merck’s Keytruda (pembrol...   \n",
      "5   keytruda  Dec 15, 2023  ApprovalPadcev (enfortumab vedotin-ejfv) with ...   \n",
      "6   keytruda  Nov 16, 2023  ApprovalFDA Approves Merck’s Keytruda (pembrol...   \n",
      "7   keytruda  Nov  1, 2023  ApprovalFDA Approves Merck’s Keytruda (pembrol...   \n",
      "8   keytruda  Oct 16, 2023  ApprovalFDA Approves Keytruda (pembrolizumab) ...   \n",
      "9   keytruda  Apr  3, 2023  ApprovalFDA Approves Merck’s Keytruda (pembrol...   \n",
      "10  keytruda  Mar 29, 2023  ApprovalFDA Converts to Full Approval Indicati...   \n",
      "11  keytruda  Jan 27, 2023  ApprovalFDA Approves Keytruda (pembrolizumab) ...   \n",
      "12  keytruda  Mar 21, 2022  ApprovalFDA Approves Merck’s Keytruda (pembrol...   \n",
      "13  keytruda  Nov 18, 2021  ApprovalFDA Approves Merck’s Keytruda (pembrol...   \n",
      "14  keytruda  Oct 13, 2021  ApprovalFDA Approves Merck’s Keytruda (pembrol...   \n",
      "15  keytruda  Aug 11, 2021  ApprovalFDA Approves Keytruda (pembrolizumab) ...   \n",
      "16  keytruda  Jul 27, 2021  ApprovalFDA Approves Keytruda (pembrolizumab) ...   \n",
      "17  keytruda  Jul 22, 2021  ApprovalFDA Approves Keytruda (pembrolizumab) ...   \n",
      "18  keytruda  Jul  6, 2021  ApprovalFDA Approves Expanded Indication for M...   \n",
      "19  keytruda  May  5, 2021  ApprovalFDA Approves Merck’s Keytruda (pembrol...   \n",
      "20  keytruda  Mar 23, 2021  ApprovalFDA Approves Merck’s Keytruda (pembrol...   \n",
      "21  keytruda  Nov 13, 2020  ApprovalFDA Approves Merck’s Keytruda (pembrol...   \n",
      "22  keytruda  Oct 15, 2020  ApprovalFDA Approves Expanded Indication for M...   \n",
      "23  keytruda  Jun 29, 2020  ApprovalFDA Approves Merck’s Keytruda (pembrol...   \n",
      "24  keytruda  Jun 24, 2020  ApprovalFDA Approves Merck’s Keytruda (pembrol...   \n",
      "25  keytruda  Jun 17, 2020  ApprovalFDA Approves Second Biomarker-Based In...   \n",
      "26  keytruda  Apr 28, 2020  ApprovalFDA Approves Merck’s Keytruda (pembrol...   \n",
      "27  keytruda  Jan  8, 2020  ApprovalFDA Approves Keytruda (pembrolizumab) ...   \n",
      "28  keytruda  Sep 17, 2019  ApprovalFDA Approves Keytruda (pembrolizumab) ...   \n",
      "29  keytruda  Jul 31, 2019  ApprovalFDA Approves Keytruda (pembrolizumab) ...   \n",
      "30  keytruda  Jun 18, 2019  ApprovalFDA Approves Keytruda (pembrolizumab) ...   \n",
      "31  keytruda  Jun 11, 2019  ApprovalFDA Approves Keytruda (pembrolizumab) ...   \n",
      "32  keytruda  Apr 22, 2019  ApprovalFDA Approves Keytruda (pembrolizumab) ...   \n",
      "33  keytruda  Apr 11, 2019  ApprovalFDA Approves Expanded Monotherapy Labe...   \n",
      "34  keytruda  Feb 19, 2019  ApprovalFDA Approves Keytruda (pembrolizumab) ...   \n",
      "35  keytruda  Dec 19, 2018  ApprovalFDA Approves Keytruda (pembrolizumab) ...   \n",
      "36  keytruda  Nov  9, 2018  ApprovalFDA Approves Keytruda (pembrolizumab) ...   \n",
      "37  keytruda  Oct 30, 2018  ApprovalFDA Approves Keytruda (pembrolizumab) ...   \n",
      "38  keytruda  Aug 21, 2018  ApprovalFDA Approves Expanded Label for Merck’...   \n",
      "39  keytruda  Jun 13, 2018  ApprovalFDA Approves Keytruda (pembrolizumab) ...   \n",
      "40  keytruda  Jun 12, 2018  ApprovalFDA Approves Keytruda (pembrolizumab) ...   \n",
      "41  keytruda  Sep 22, 2017  ApprovalFDA Approves Merck’s Keytruda (pembrol...   \n",
      "42  keytruda  May 23, 2017  ApprovalFDA Approves Keytruda (pembrolizumab) ...   \n",
      "43  keytruda  May 18, 2017  ApprovalFDA Approves Merck’s Keytruda (pembrol...   \n",
      "44  keytruda  May 10, 2017  ApprovalFDA Approves Merck’s Keytruda (pembrol...   \n",
      "45  keytruda  Mar 15, 2017  ApprovalFDA Approves Merck’s Keytruda (pembrol...   \n",
      "46  keytruda  Oct 24, 2016  ApprovalFDA Approves Merck’s Keytruda (pembrol...   \n",
      "47  keytruda  Aug  5, 2016  ApprovalFDA Approves Merck’s Keytruda (pembrol...   \n",
      "48  keytruda  Dec 18, 2015  ApprovalFDA Approves Expanded Indication for K...   \n",
      "49  keytruda  Oct  2, 2015  ApprovalFDA Approves Keytruda (pembrolizumab) ...   \n",
      "50  keytruda  Sep  4, 2014  ApprovalFDA Approves Keytruda (pembrolizumab) ...   \n",
      "\n",
      "                                            url  \n",
      "0   https://www.drugs.com/history/keytruda.html  \n",
      "1   https://www.drugs.com/history/keytruda.html  \n",
      "2   https://www.drugs.com/history/keytruda.html  \n",
      "3   https://www.drugs.com/history/keytruda.html  \n",
      "4   https://www.drugs.com/history/keytruda.html  \n",
      "5   https://www.drugs.com/history/keytruda.html  \n",
      "6   https://www.drugs.com/history/keytruda.html  \n",
      "7   https://www.drugs.com/history/keytruda.html  \n",
      "8   https://www.drugs.com/history/keytruda.html  \n",
      "9   https://www.drugs.com/history/keytruda.html  \n",
      "10  https://www.drugs.com/history/keytruda.html  \n",
      "11  https://www.drugs.com/history/keytruda.html  \n",
      "12  https://www.drugs.com/history/keytruda.html  \n",
      "13  https://www.drugs.com/history/keytruda.html  \n",
      "14  https://www.drugs.com/history/keytruda.html  \n",
      "15  https://www.drugs.com/history/keytruda.html  \n",
      "16  https://www.drugs.com/history/keytruda.html  \n",
      "17  https://www.drugs.com/history/keytruda.html  \n",
      "18  https://www.drugs.com/history/keytruda.html  \n",
      "19  https://www.drugs.com/history/keytruda.html  \n",
      "20  https://www.drugs.com/history/keytruda.html  \n",
      "21  https://www.drugs.com/history/keytruda.html  \n",
      "22  https://www.drugs.com/history/keytruda.html  \n",
      "23  https://www.drugs.com/history/keytruda.html  \n",
      "24  https://www.drugs.com/history/keytruda.html  \n",
      "25  https://www.drugs.com/history/keytruda.html  \n",
      "26  https://www.drugs.com/history/keytruda.html  \n",
      "27  https://www.drugs.com/history/keytruda.html  \n",
      "28  https://www.drugs.com/history/keytruda.html  \n",
      "29  https://www.drugs.com/history/keytruda.html  \n",
      "30  https://www.drugs.com/history/keytruda.html  \n",
      "31  https://www.drugs.com/history/keytruda.html  \n",
      "32  https://www.drugs.com/history/keytruda.html  \n",
      "33  https://www.drugs.com/history/keytruda.html  \n",
      "34  https://www.drugs.com/history/keytruda.html  \n",
      "35  https://www.drugs.com/history/keytruda.html  \n",
      "36  https://www.drugs.com/history/keytruda.html  \n",
      "37  https://www.drugs.com/history/keytruda.html  \n",
      "38  https://www.drugs.com/history/keytruda.html  \n",
      "39  https://www.drugs.com/history/keytruda.html  \n",
      "40  https://www.drugs.com/history/keytruda.html  \n",
      "41  https://www.drugs.com/history/keytruda.html  \n",
      "42  https://www.drugs.com/history/keytruda.html  \n",
      "43  https://www.drugs.com/history/keytruda.html  \n",
      "44  https://www.drugs.com/history/keytruda.html  \n",
      "45  https://www.drugs.com/history/keytruda.html  \n",
      "46  https://www.drugs.com/history/keytruda.html  \n",
      "47  https://www.drugs.com/history/keytruda.html  \n",
      "48  https://www.drugs.com/history/keytruda.html  \n",
      "49  https://www.drugs.com/history/keytruda.html  \n",
      "50  https://www.drugs.com/history/keytruda.html  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "drugname = \"keytruda\"\n",
    "url = f\"https://www.drugs.com/history/{drugname}.html\"\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "rows = []\n",
    "\n",
    "# --- Grab the first table on the page (should be history)\n",
    "table = soup.find(\"table\")\n",
    "if table:\n",
    "    for tr in table.find_all(\"tr\"):\n",
    "        tds = tr.find_all(\"td\")\n",
    "        if len(tds) >= 2:\n",
    "            date = tds[0].get_text(strip=True)\n",
    "            details = tds[1].get_text(strip=True)\n",
    "            # Filter only approval rows (case-insensitive, matches at start)\n",
    "            if details.lower().startswith(\"approval\"):\n",
    "                rows.append({\"drugname\": drugname, \"date\": date, \"details\": details, \"url\": url})\n",
    "\n",
    "# --- Fallback to the old structure (ul/li, rarely needed now)\n",
    "if not rows:\n",
    "    for entry in soup.find_all(\"li\", class_=\"ddc-history-event\"):\n",
    "        label = entry.find(\"span\", class_=\"label\")\n",
    "        if label and \"Approval\" in label.text:\n",
    "            date = entry.find(\"span\", class_=\"date\").text.strip()\n",
    "            article = entry.find(\"span\", class_=\"title\").text.strip()\n",
    "            rows.append({\"drugname\": drugname, \"date\": date, \"details\": article, \"url\": url})\n",
    "\n",
    "df_drug = pd.DataFrame(rows)\n",
    "print(df_drug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3696a6-b5ad-4080-9737-132323dd407c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "drugname = \"keytruda\"   # Or any other drug\n",
    "url = f\"https://www.drugs.com/history/{drugname}.html\"\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "rows = []\n",
    "\n",
    "# Handle table structure (e.g., ayvakit)\n",
    "table = soup.find(\"table\")\n",
    "if table:\n",
    "    for tr in table.find_all(\"tr\"):\n",
    "        tds = tr.find_all(\"td\")\n",
    "        if len(tds) >= 2:\n",
    "            date = tds[0].get_text(strip=True)\n",
    "            details = tds[1].get_text(strip=True)\n",
    "            if details.lower().startswith(\"approval\"):\n",
    "                rows.append({\n",
    "                    \"drugname\": drugname,\n",
    "                    \"date\": date,\n",
    "                    \"details\": details,\n",
    "                    \"url\": url,\n",
    "                    \"green_badge\": None    # Can't tell from table\n",
    "                })\n",
    "# Handle list/badge structure (e.g., keytruda)\n",
    "else:\n",
    "    for entry in soup.find_all(\"li\", class_=\"ddc-history-event\"):\n",
    "        label = entry.find(\"span\", class_=\"label\")\n",
    "        if label and \"Approval\" in label.text:\n",
    "            date = entry.find(\"span\", class_=\"date\").text.strip()\n",
    "            article = entry.find(\"span\", class_=\"title\").text.strip()\n",
    "            # Check if badge is green\n",
    "            label_classes = label.get(\"class\", [])\n",
    "            is_green = \"success\" in label_classes\n",
    "            rows.append({\n",
    "                \"drugname\": drugname,\n",
    "                \"date\": date,\n",
    "                \"details\": article,\n",
    "                \"url\": url,\n",
    "                \"green_badge\": is_green\n",
    "            })\n",
    "\n",
    "df_drug = pd.DataFrame(rows)\n",
    "print(df_drug)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
